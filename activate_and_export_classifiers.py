# ðŸŽ¯ Activate and Export New Trained Models for Classification

import json
import os
import shutil
from datetime import datetime
import zipfile

def main():
    print("ðŸŽ¯ Activating New Trained Models for Classification & Export")
    print("=" * 65)
    
    # Paths
    registry_path = "models/registry/model_registry.json"
    models_dir = "models"
    export_dir = "exported_models"
    new_models_dir = "new"
    
    # Create export directory if it doesn't exist
    os.makedirs(export_dir, exist_ok=True)
    
    # Define classification model mappings with clear naming
    classification_models = {
        "pneumonia_classifier": {
            "source": "new/densenet121_pneumonia_intensive_models/models/densenet121_pneumonia_intensive_20251006_182328.h5",
            "keras_source": "new/densenet121_pneumonia_intensive_models/models/densenet121_pneumonia_intensive_20251006_182328.keras",
            "details": "new/densenet121_pneumonia_intensive_models/model_details.json",
            "target": "pneumonia_classifier_v2.h5",
            "export_name": "Pneumonia_Detection_Model_95.8_Accuracy.h5",
            "classification": "Pneumonia Detection",
            "description": "AI model for detecting pneumonia in chest X-rays",
            "accuracy": 95.8,
            "classes": ["Normal", "Pneumonia"],
            "input_type": "Chest X-Ray",
            "medical_condition": "Respiratory"
        },
        "arthritis_classifier": {
            "source": "new/densenet121_osteoarthritis_intensive_models/models/densenet121_osteoarthritis_intensive_20251006_185456.h5",
            "keras_source": "new/densenet121_osteoarthritis_intensive_models/models/densenet121_osteoarthritis_intensive_20251006_185456.keras",
            "details": "new/densenet121_osteoarthritis_intensive_models/model_details.json", 
            "target": "arthritis_classifier_v2.h5",
            "export_name": "Arthritis_Detection_Model_94.2_Accuracy.h5",
            "classification": "Knee Arthritis Detection", 
            "description": "AI model for detecting osteoarthritis in knee X-rays",
            "accuracy": 94.2,
            "classes": ["Normal", "Osteoarthritis"],
            "input_type": "Knee X-Ray",
            "medical_condition": "Orthopedic"
        },
        "osteoporosis_classifier": {
            "source": "new/densenet121_osteoporosis_intensive_models/models/densenet121_osteoporosis_intensive_20251006_183913.h5",
            "keras_source": "new/densenet121_osteoporosis_intensive_models/models/densenet121_osteoporosis_intensive_20251006_183913.keras",
            "details": "new/densenet121_osteoporosis_intensive_models/model_details.json",
            "target": "osteoporosis_classifier_v2.h5", 
            "export_name": "Osteoporosis_Detection_Model_91.8_Accuracy.h5",
            "classification": "Bone Density Assessment",
            "description": "AI model for detecting osteoporosis in knee X-rays", 
            "accuracy": 91.8,
            "classes": ["Normal", "Osteoporosis"],
            "input_type": "Knee X-Ray",
            "medical_condition": "Orthopedic"
        },
        "bone_fracture_classifier": {
            "source": "new/densenet121_limbabnormalities_intensive_models/models/densenet121_limbabnormalities_intensive_20251006_190347.h5",
            "keras_source": "new/densenet121_limbabnormalities_intensive_models/models/densenet121_limbabnormalities_intensive_20251006_190347.keras",
            "details": "new/densenet121_limbabnormalities_intensive_models/model_details.json",
            "target": "bone_fracture_classifier_v2.h5",
            "export_name": "Bone_Fracture_Detection_Model_73.0_Accuracy.h5", 
            "classification": "Bone Fracture Detection",
            "description": "AI model for detecting fractures in limb X-rays",
            "accuracy": 73.0,
            "classes": ["Normal", "Fracture"],
            "input_type": "Limb X-Ray (Arm/Forearm)",
            "medical_condition": "Trauma/Emergency"
        },
        "cardiomegaly_classifier": {
            "source": "new/cardiomegaly_densenet121/cardiomegaly_intensive_20251006_192404/cardiomegaly_densenet121_intensive_20251006_192404.h5",
            "keras_source": "new/cardiomegaly_densenet121/cardiomegaly_intensive_20251006_192404/cardiomegaly_densenet121_intensive_20251006_192404.keras", 
            "details": "new/cardiomegaly_densenet121/cardiomegaly_intensive_20251006_192404/model_details.json",
            "target": "cardiomegaly_classifier_v2.h5",
            "export_name": "Cardiomegaly_Detection_Model_63.0_Accuracy.h5",
            "classification": "Heart Enlargement Detection", 
            "description": "AI model for detecting cardiomegaly in chest X-rays",
            "accuracy": 63.0,
            "classes": ["Normal", "Cardiomegaly"], 
            "input_type": "Chest X-Ray",
            "medical_condition": "Cardiac"
        }
    }
    
    print(f"\nðŸŽ¯ Processing {len(classification_models)} classification models...")
    
    # Load current registry
    with open(registry_path, 'r') as f:
        registry = json.load(f)
    
    # Backup registry
    backup_path = f"models/registry/model_registry_classifier_activation_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    shutil.copy2(registry_path, backup_path)
    print(f"ðŸ“¦ Backed up registry to: {backup_path}")
    
    activated_models = []
    export_info = []
    
    for classifier_name, config in classification_models.items():
        print(f"\nðŸ“‹ Processing {classifier_name}...")
        
        # Check if source file exists
        source_path = config["source"]
        keras_path = config.get("keras_source", "")
        
        if not os.path.exists(source_path):
            print(f"   âŒ Source model not found: {source_path}")
            continue
            
        # Copy to models directory with classifier naming
        target_path = os.path.join(models_dir, config["target"])
        export_path = os.path.join(export_dir, config["export_name"])
        
        try:
            # Copy to models directory
            shutil.copy2(source_path, target_path)
            source_size = round(os.path.getsize(source_path) / (1024 * 1024), 2)
            
            # Copy to export directory with descriptive name
            shutil.copy2(source_path, export_path)
            
            print(f"   âœ… Activated: {config['target']} ({source_size} MB)")
            print(f"   ðŸ“¦ Exported: {config['export_name']}")
            
            # Also copy keras version if available
            if os.path.exists(keras_path):
                keras_export = export_path.replace('.h5', '.keras')
                shutil.copy2(keras_path, keras_export)
                print(f"   ðŸ“¦ Exported Keras: {os.path.basename(keras_export)}")
            
        except Exception as e:
            print(f"   âŒ Failed to process model: {str(e)}")
            continue
        
        # Load model details
        model_details = {}
        if os.path.exists(config["details"]):
            try:
                with open(config["details"], 'r') as f:
                    model_details = json.load(f)
            except Exception as e:
                print(f"   âš ï¸ Could not load details: {str(e)}")
        
        # Create registry entry for classifier
        dataset_type = classifier_name.replace("_classifier", "")
        model_id = f"{dataset_type}_classifier_v2"
        
        registry_entry = {
            "model_id": model_id,
            "model_name": f"DenseNet121 {config['classification']} Classifier",
            "dataset_type": dataset_type,
            "classifier_name": classifier_name,
            "version": "2.0_classifier",
            "architecture": "DenseNet121",
            "input_shape": [224, 224, 3],
            "num_classes": 2,
            "class_names": config["classes"],
            "classes": config["classes"],
            "classification_task": config["classification"],
            "input_type": config["input_type"],
            "medical_condition": config["medical_condition"],
            "performance_metrics": {
                "accuracy": config["accuracy"] / 100,
                "test_accuracy": config["accuracy"] / 100
            },
            "accuracy": config["accuracy"] / 100,
            "training_info": {
                "training_date": "2025-10-06",
                "performance_level": "Medical Grade" if config["accuracy"] >= 90 else "Research Grade",
                "clinical_readiness": "Ready for Clinical Use" if config["accuracy"] >= 90 else "Research Phase"
            },
            "file_path": config["target"],
            "export_path": config["export_name"],
            "file_size": source_size,
            "created_date": "2025-10-06",
            "description": config["description"],
            "tags": [
                "DenseNet121",
                "medical",
                "classifier",
                dataset_type,
                "exported"
            ],
            "gradcam_layer": "conv5_block16_2_conv",
            "is_active": True,
            "is_classifier": True,
            "source_path": source_path
        }
        
        # Add to registry
        registry["models"][model_id] = registry_entry
        
        # Update active models
        registry["active_models"][dataset_type] = model_id
        
        activated_models.append({
            "classifier": classifier_name,
            "model_id": model_id,
            "accuracy": config["accuracy"],
            "classification": config["classification"],
            "export_file": config["export_name"]
        })
        
        # Create export documentation
        export_info.append({
            "model_name": config["export_name"],
            "classification_task": config["classification"],
            "accuracy": f"{config['accuracy']}%",
            "input_type": config["input_type"],
            "classes": config["classes"],
            "description": config["description"],
            "medical_condition": config["medical_condition"],
            "file_size_mb": source_size,
            "architecture": "DenseNet121",
            "usage": f"Load with tf.keras.models.load_model('{config['export_name']}')"
        })
        
        print(f"   âœ… Activated classifier: {model_id}")
        print(f"   ðŸ“Š Classification: {config['classification']} ({config['accuracy']}% accuracy)")
    
    # Update registry metadata
    registry["last_modified"] = datetime.now().isoformat()
    registry["version"] = "2.5_classifiers"
    
    # Save updated registry
    with open(registry_path, 'w') as f:
        json.dump(registry, f, indent=2)
    
    # Create comprehensive export documentation
    export_doc = {
        "export_date": datetime.now().isoformat(),
        "total_models": len(export_info),
        "models": export_info,
        "usage_instructions": {
            "loading": "import tensorflow as tf; model = tf.keras.models.load_model('model_file.h5')",
            "preprocessing": "Resize images to 224x224, normalize pixel values to [0,1]",
            "prediction": "predictions = model.predict(preprocessed_image)",
            "interpretation": "Use argmax for class prediction, softmax outputs for probabilities"
        },
        "system_requirements": {
            "tensorflow": ">=2.10.0",
            "python": ">=3.8",
            "memory": "4GB RAM minimum", 
            "storage": "200MB per model"
        }
    }
    
    # Save export documentation
    doc_path = os.path.join(export_dir, "MODEL_EXPORT_DOCUMENTATION.json")
    with open(doc_path, 'w', encoding='utf-8') as f:
        json.dump(export_doc, f, indent=2)
    
    # Create user-friendly README for exported models
    readme_content = f"""# Medical X-Ray AI Classification Models

**Export Date:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**Total Models:** {len(export_info)}
**Architecture:** DenseNet121

## Available Classification Models

"""

    for model in export_info:
        readme_content += f"""### {model['classification_task']}
- **File:** `{model['model_name']}`
- **Accuracy:** {model['accuracy']}
- **Input:** {model['input_type']}
- **Classes:** {', '.join(model['classes'])}
- **Medical Field:** {model['medical_condition']}
- **Description:** {model['description']}

"""

    readme_content += f"""
## Quick Usage Guide

### 1. Load Model
```python
import tensorflow as tf
import numpy as np
from PIL import Image

# Load the model
model = tf.keras.models.load_model('Pneumonia_Detection_Model_95.8_Accuracy.h5')
```

### 2. Preprocess Image
```python
def preprocess_image(image_path):
    image = Image.open(image_path)
    image = image.resize((224, 224))
    image_array = np.array(image) / 255.0
    return np.expand_dims(image_array, axis=0)
```

### 3. Make Prediction
```python
# Preprocess your X-ray image
processed_image = preprocess_image('xray_image.jpg')

# Get prediction
prediction = model.predict(processed_image)
class_index = np.argmax(prediction[0])
confidence = np.max(prediction[0])

print(f"Predicted class: {{class_index}}")
print(f"Confidence: {{confidence:.2%}}")
```

## Model Performance

| Model | Accuracy | Clinical Status |
|-------|----------|-----------------|
"""

    for model in export_info:
        clinical_status = "Medical Grade" if float(model['accuracy'].replace('%', '')) >= 90 else "Research Grade"
        readme_content += f"| {model['classification_task']} | {model['accuracy']} | {clinical_status} |\n"

    readme_content += f"""
## System Requirements

- **Python:** 3.8 or higher
- **TensorFlow:** 2.10.0 or higher  
- **Memory:** 4GB RAM minimum
- **Storage:** ~200MB per model

## Support

For technical support or questions about these models, please refer to the project documentation.

---
**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**Total Models Exported:** {len(export_info)}
"""

    readme_path = os.path.join(export_dir, "README.md")
    with open(readme_path, 'w', encoding='utf-8') as f:
        f.write(readme_content)
    
    # Create a zip file of all exported models
    zip_path = os.path.join(export_dir, f"Medical_AI_Models_Export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip")
    with zipfile.ZipFile(zip_path, 'w') as zipf:
        for model in export_info:
            model_path = os.path.join(export_dir, model['model_name'])
            if os.path.exists(model_path):
                zipf.write(model_path, model['model_name'])
        
        # Add documentation
        zipf.write(doc_path, "MODEL_EXPORT_DOCUMENTATION.json")
        zipf.write(readme_path, "README.md")
    
    print(f"\nâœ… Classification Models Activation & Export Complete!")
    print(f"ðŸ“Š Total models activated: {len(activated_models)}")
    print(f"ðŸ“¦ Export directory: {export_dir}")
    print(f"ðŸ“‹ Documentation: {readme_path}")
    print(f"ðŸ—œï¸ Zip archive: {zip_path}")
    
    print(f"\nðŸŽ¯ ACTIVATED CLASSIFIERS:")
    for model in activated_models:
        status = "ðŸ… Medical Grade" if model['accuracy'] >= 90 else "ðŸ”¬ Research Grade"
        print(f"   â€¢ {model['classification']}: {model['accuracy']}% accuracy {status}")
    
    print(f"\nðŸ“¦ EXPORTED MODELS:")
    for model in export_info:
        print(f"   â€¢ {model['model_name']} ({model['file_size_mb']} MB)")
    
    print(f"\nðŸš€ READY FOR USE:")
    print(f"   1. Models are activated in the classification system")
    print(f"   2. Exported models available in '{export_dir}' directory")
    print(f"   3. Users can download and use individual model files")
    print(f"   4. Complete package available as ZIP archive")
    print(f"   5. Documentation included for easy integration")

if __name__ == "__main__":
    main()