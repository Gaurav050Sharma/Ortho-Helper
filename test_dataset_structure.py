#!/usr/bin/env python3
"""
Test script to verify the dataset structure and code compatibility
after reorganizing the Dataset folder into ARM/CHEST/KNEE structure
"""

import os
import sys
from pathlib import Path

def test_dataset_structure():
    """Test the new dataset structure"""
    print("=" * 60)
    print("ğŸ” DATASET STRUCTURE VERIFICATION")
    print("=" * 60)
    
    base_path = Path("Dataset")
    
    if not base_path.exists():
        print("âŒ Dataset folder not found!")
        return False
    
    # Expected structure
    expected_structure = {
        "ARM": ["MURA_Organized"],
        "CHEST": ["cardiomelgy", "Pneumonia_Organized"],
        "KNEE": ["Osteoarthritis", "Osteoporosis"]
    }
    
    all_good = True
    
    for category, expected_folders in expected_structure.items():
        category_path = base_path / category
        print(f"\nğŸ“ Checking {category} folder...")
        
        if not category_path.exists():
            print(f"âŒ {category} folder not found!")
            all_good = False
            continue
        
        print(f"âœ… {category} folder exists")
        
        # Check subfolders
        for folder in expected_folders:
            folder_path = category_path / folder
            if folder_path.exists():
                print(f"  âœ… {folder} found")
                
                # Count images in each folder
                image_count = count_images(folder_path)
                print(f"    ğŸ“Š Contains {image_count} image files")
            else:
                print(f"  âŒ {folder} not found!")
                all_good = False
    
    return all_good

def count_images(path):
    """Count image files recursively"""
    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.dcm', '.dicom']
    count = 0
    
    for ext in image_extensions:
        count += len(list(path.rglob(f"*{ext}")))
        count += len(list(path.rglob(f"*{ext.upper()}")))
    
    return count

def test_data_loader():
    """Test the data loader with new structure"""
    print("\n" + "=" * 60)
    print("ğŸ§ª DATA LOADER COMPATIBILITY TEST")
    print("=" * 60)
    
    try:
        from utils.data_loader import MedicalDataLoader
        
        print("âœ… Data loader imported successfully")
        
        # Create loader instance
        loader = MedicalDataLoader()
        print("âœ… Data loader initialized")
        
        # Scan datasets
        print("\nğŸ“Š Scanning datasets...")
        dataset_info = loader.scan_datasets()
        
        if not dataset_info:
            print("âŒ No datasets found!")
            return False
        
        # Check each dataset
        for dataset_name, info in dataset_info.items():
            print(f"\nğŸ“ Dataset: {dataset_name}")
            print(f"  ğŸ“Š Total images: {info['total_images']}")
            print(f"  ğŸ“‚ Sources found: {len(info['sources_found'])}")
            print(f"  ğŸ·ï¸ Classes: {list(info['class_distribution'].keys())}")
            print(f"  âœ… Ready for training: {info['ready_for_training']}")
        
        print("\nâœ… Data loader test completed successfully!")
        return True
        
    except Exception as e:
        print(f"âŒ Data loader test failed: {str(e)}")
        return False

def test_model_loading():
    """Test model loading functionality"""
    print("\n" + "=" * 60)
    print("ğŸ¤– MODEL LOADING TEST")
    print("=" * 60)
    
    try:
        from utils.model_inference import load_models
        
        print("âœ… Model inference module imported successfully")
        
        # Test model loading
        print("ğŸ”„ Loading models...")
        models = load_models()
        
        if models:
            print("âœ… Models loaded successfully!")
            print(f"ğŸ“Š Found {len(models)} models:")
            for model_name in models.keys():
                print(f"  â€¢ {model_name}")
        else:
            print("âš ï¸ No models loaded - this might be expected if models haven't been trained yet")
        
        return True
        
    except Exception as e:
        print(f"âŒ Model loading test failed: {str(e)}")
        return False

def test_app_imports():
    """Test main app imports"""
    print("\n" + "=" * 60)
    print("ğŸ“± MAIN APP COMPATIBILITY TEST")
    print("=" * 60)
    
    try:
        # Test critical imports
        print("ğŸ”„ Testing imports...")
        
        import streamlit as st
        print("âœ… Streamlit imported")
        
        from utils.data_loader import display_dataset_overview, MedicalDataLoader
        print("âœ… Data loader utilities imported")
        
        from utils.model_inference import load_models
        print("âœ… Model inference imported")
        
        print("âœ… All critical imports successful!")
        return True
        
    except Exception as e:
        print(f"âŒ Import test failed: {str(e)}")
        return False

def check_model_files():
    """Check if model files exist"""
    print("\n" + "=" * 60)
    print("ğŸ—ï¸ MODEL FILES CHECK")
    print("=" * 60)
    
    models_path = Path("models")
    
    if not models_path.exists():
        print("âŒ Models folder not found!")
        return False
    
    # Expected model files
    expected_models = [
        "bone_fracture_model.h5",
        "cardiomegaly_binary_model.h5",
        "cardiomegaly_DenseNet121_model.h5",
        "chest_conditions_DenseNet121_model.h5",
        "knee_conditions_DenseNet121_model.h5"
    ]
    
    found_models = []
    missing_models = []
    
    for model_file in expected_models:
        model_path = models_path / model_file
        if model_path.exists():
            found_models.append(model_file)
            print(f"âœ… {model_file}")
        else:
            missing_models.append(model_file)
            print(f"âŒ {model_file} - Missing")
    
    print(f"\nğŸ“Š Summary: {len(found_models)} found, {len(missing_models)} missing")
    
    return len(found_models) > 0

def main():
    """Run all tests"""
    print("ğŸš€ COMPLETE SYSTEM VERIFICATION")
    print("Testing compatibility after Dataset folder reorganization")
    print("Date:", "October 6, 2025")
    
    tests = [
        ("Dataset Structure", test_dataset_structure),
        ("Data Loader", test_data_loader),
        ("Model Files", check_model_files),
        ("Model Loading", test_model_loading),
        ("App Imports", test_app_imports)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"âŒ {test_name} test crashed: {str(e)}")
            results.append((test_name, False))
    
    # Final summary
    print("\n" + "=" * 60)
    print("ğŸ“Š FINAL SUMMARY")
    print("=" * 60)
    
    passed = 0
    total = len(results)
    
    for test_name, result in results:
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"{status} - {test_name}")
        if result:
            passed += 1
    
    print(f"\nğŸ¯ Overall Result: {passed}/{total} tests passed")
    
    if passed == total:
        print("ğŸ‰ ALL TESTS PASSED! Your code is compatible with the new dataset structure.")
    elif passed >= total * 0.8:
        print("âš ï¸ Most tests passed. Minor issues may need attention.")
    else:
        print("âŒ Several tests failed. Please check the issues above.")
    
    print("\nğŸ’¡ Recommendations:")
    if not results[0][1]:  # Dataset structure failed
        print("â€¢ Fix the dataset folder organization")
    if not results[1][1]:  # Data loader failed
        print("â€¢ Update data loader paths")
    if not results[2][1]:  # Model files failed
        print("â€¢ Train or download the required models")
    if not results[3][1] or not results[4][1]:  # Model/app issues
        print("â€¢ Check dependencies and imports")
    
    print("â€¢ Run the Streamlit app and test each feature manually")

if __name__ == "__main__":
    main()